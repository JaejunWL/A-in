{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torchinfo import summary\n",
    "\n",
    "import easydict\n",
    "\n",
    "from network_module import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = easydict.EasyDict({\n",
    "    \"data_dir\": '../dataset',\n",
    "    \"input_length\": 220500,\n",
    "    \"image_height\": 1025,\n",
    "    \"image_width\": 431,\n",
    "    \"bbox_shape\": 120,\n",
    "    \"mask_type\": 'time_masking',\n",
    "    \"in_channels\" : 2,\n",
    "    \"out_channels\" : 1,\n",
    "    \"latent_channels\" : 32,\n",
    "    \"pad_type\": 'zero',\n",
    "    \"activation\": 'lrelu',\n",
    "    \"norm\":'in',\n",
    "    \"init_type\":'xavier',\n",
    "    \"init_gain\":0.02,\n",
    "    \"stage_num\": 1,\n",
    "    \"batch_size\": 4,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(PatchDiscriminator, self).__init__()\n",
    "        # Down sampling\n",
    "        self.block1 = Conv2dLayer(opt.in_channels, opt.latent_channels, 7, 1, 3, pad_type = opt.pad_type, activation = opt.activation, norm = 'none', sn = 0)\n",
    "        self.block2 = Conv2dLayer(opt.latent_channels, opt.latent_channels * 2, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block3 = Conv2dLayer(opt.latent_channels * 2, opt.latent_channels * 4, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block4 = Conv2dLayer(opt.latent_channels * 4, opt.latent_channels * 4, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block5 = Conv2dLayer(opt.latent_channels * 4, opt.latent_channels * 4, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block6 = Conv2dLayer(opt.latent_channels * 4, 1, 4, 2, 1, pad_type = opt.pad_type, activation = 'none', norm = 'none', sn = 0)\n",
    "        \n",
    "    def forward(self, img, mask):\n",
    "        # the input x should contain 4 channels because it is a combination of recon image and mask\n",
    "        x = torch.cat((img, mask), 1)\n",
    "        x = self.block1(x)                                      # out: [B, 64, 256, 256]\n",
    "        x = self.block2(x)                                      # out: [B, 128, 128, 128]\n",
    "        x = self.block3(x)                                      # out: [B, 256, 64, 64]\n",
    "        x = self.block4(x)                                      # out: [B, 256, 32, 32]\n",
    "        x = self.block5(x)                                      # out: [B, 256, 16, 16]\n",
    "        x = self.block6(x)                                      # out: [B, 256, 8, 8]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "PatchDiscriminator                       --                        --\n",
       "├─Conv2dLayer: 1-1                       [4, 32, 1024, 428]        --\n",
       "│    └─ZeroPad2d: 2-1                    [4, 2, 1030, 434]         --\n",
       "│    └─Conv2d: 2-2                       [4, 32, 1024, 428]        3,168\n",
       "│    └─LeakyReLU: 2-3                    [4, 32, 1024, 428]        --\n",
       "├─Conv2dLayer: 1-2                       [4, 64, 512, 214]         --\n",
       "│    └─ZeroPad2d: 2-4                    [4, 32, 1026, 430]        --\n",
       "│    └─Conv2d: 2-5                       [4, 64, 512, 214]         32,832\n",
       "│    └─InstanceNorm2d: 2-6               [4, 64, 512, 214]         --\n",
       "│    └─LeakyReLU: 2-7                    [4, 64, 512, 214]         --\n",
       "├─Conv2dLayer: 1-3                       [4, 128, 256, 107]        --\n",
       "│    └─ZeroPad2d: 2-8                    [4, 64, 514, 216]         --\n",
       "│    └─Conv2d: 2-9                       [4, 128, 256, 107]        131,200\n",
       "│    └─InstanceNorm2d: 2-10              [4, 128, 256, 107]        --\n",
       "│    └─LeakyReLU: 2-11                   [4, 128, 256, 107]        --\n",
       "├─Conv2dLayer: 1-4                       [4, 128, 128, 53]         --\n",
       "│    └─ZeroPad2d: 2-12                   [4, 128, 258, 109]        --\n",
       "│    └─Conv2d: 2-13                      [4, 128, 128, 53]         262,272\n",
       "│    └─InstanceNorm2d: 2-14              [4, 128, 128, 53]         --\n",
       "│    └─LeakyReLU: 2-15                   [4, 128, 128, 53]         --\n",
       "├─Conv2dLayer: 1-5                       [4, 128, 64, 26]          --\n",
       "│    └─ZeroPad2d: 2-16                   [4, 128, 130, 55]         --\n",
       "│    └─Conv2d: 2-17                      [4, 128, 64, 26]          262,272\n",
       "│    └─InstanceNorm2d: 2-18              [4, 128, 64, 26]          --\n",
       "│    └─LeakyReLU: 2-19                   [4, 128, 64, 26]          --\n",
       "├─Conv2dLayer: 1-6                       [4, 1, 32, 13]            --\n",
       "│    └─ZeroPad2d: 2-20                   [4, 128, 66, 28]          --\n",
       "│    └─Conv2d: 2-21                      [4, 1, 32, 13]            2,049\n",
       "==========================================================================================\n",
       "Total params: 693,793\n",
       "Trainable params: 693,793\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 43.18\n",
       "==========================================================================================\n",
       "Input size (MB): 14.02\n",
       "Forward/backward pass size (MB): 820.00\n",
       "Params size (MB): 2.78\n",
       "Estimated Total Size (MB): 836.80\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = PatchDiscriminator(opt)\n",
    "summary(discriminator, [(4, 1, 1024, 428), (4, 1, 1024, 428)], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jj_Discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f0d28877a37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjj_Discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'jj_Discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "discriminator = jj_Discriminator(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 512, 214]           1,056\n",
      "         LeakyReLU-2         [-1, 32, 512, 214]               0\n",
      "            Conv2d-3         [-1, 64, 256, 107]          32,832\n",
      "         LeakyReLU-4         [-1, 64, 256, 107]               0\n",
      "            Conv2d-5         [-1, 128, 128, 53]         131,200\n",
      "         LeakyReLU-6         [-1, 128, 128, 53]               0\n",
      "            Conv2d-7          [-1, 256, 64, 26]         524,544\n",
      "           Sigmoid-8          [-1, 256, 64, 26]               0\n",
      "            Linear-9                    [-1, 1]         425,985\n",
      "          Sigmoid-10                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,115,617\n",
      "Trainable params: 1,115,617\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 732736.00\n",
      "Forward/backward pass size (MB): 100.00\n",
      "Params size (MB): 4.26\n",
      "Estimated Total Size (MB): 732840.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(discriminator, [(1, 1024, 428), (1, 1024, 428)], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand([4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5344), tensor(0.5344))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a), a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(PatchDiscriminator, self).__init__()\n",
    "        # Down sampling\n",
    "        self.block1 = Conv2dLayer(opt.in_channels, opt.latent_channels, 7, 1, 3, pad_type = opt.pad_type, activation = opt.activation, norm = 'none', sn = 0)\n",
    "        self.block2 = Conv2dLayer(opt.latent_channels, opt.latent_channels * 2, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block3 = Conv2dLayer(opt.latent_channels * 2, opt.latent_channels * 4, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block4 = Conv2dLayer(opt.latent_channels * 4, opt.latent_channels * 4, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block5 = Conv2dLayer(opt.latent_channels * 4, opt.latent_channels * 4, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = opt.norm, sn = 0)\n",
    "        self.block6 = Conv2dLayer(opt.latent_channels * 4, 1, 4, 2, 1, pad_type = opt.pad_type, activation = opt.activation, norm = 'none', sn = 0)\n",
    "        self.features_to_prob = nn.Sequential(\n",
    "            nn.Linear(32 * 13, 1),\n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "    def forward(self, img, mask):\n",
    "        # the input x should contain 4 channels because it is a combination of recon image and mask\n",
    "        x1 = torch.cat((img, mask), 1)\n",
    "        x = self.block1(x1)                                      # out: [B, 64, 256, 256]\n",
    "        x = self.block2(x)                                      # out: [B, 128, 128, 128]\n",
    "        x = self.block3(x)                                      # out: [B, 256, 64, 64]\n",
    "        x = self.block4(x)                                      # out: [B, 256, 32, 32]\n",
    "        x = self.block5(x)                                      # out: [B, 256, 16, 16]\n",
    "        x = self.block6(x)                                      # out: [B, 256, 8, 8]\n",
    "        batch_size = x1.shape[0]\n",
    "        x = x.view(batch_size, -1)        \n",
    "        x = self.features_to_prob(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = PatchDiscriminator(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "PatchDiscriminator                       --                        --\n",
       "├─Conv2dLayer: 1-1                       [4, 32, 1024, 428]        --\n",
       "│    └─ZeroPad2d: 2-1                    [4, 2, 1030, 434]         --\n",
       "│    └─Conv2d: 2-2                       [4, 32, 1024, 428]        3,168\n",
       "│    └─LeakyReLU: 2-3                    [4, 32, 1024, 428]        --\n",
       "├─Conv2dLayer: 1-2                       [4, 64, 512, 214]         --\n",
       "│    └─ZeroPad2d: 2-4                    [4, 32, 1026, 430]        --\n",
       "│    └─Conv2d: 2-5                       [4, 64, 512, 214]         32,832\n",
       "│    └─InstanceNorm2d: 2-6               [4, 64, 512, 214]         --\n",
       "│    └─LeakyReLU: 2-7                    [4, 64, 512, 214]         --\n",
       "├─Conv2dLayer: 1-3                       [4, 128, 256, 107]        --\n",
       "│    └─ZeroPad2d: 2-8                    [4, 64, 514, 216]         --\n",
       "│    └─Conv2d: 2-9                       [4, 128, 256, 107]        131,200\n",
       "│    └─InstanceNorm2d: 2-10              [4, 128, 256, 107]        --\n",
       "│    └─LeakyReLU: 2-11                   [4, 128, 256, 107]        --\n",
       "├─Conv2dLayer: 1-4                       [4, 128, 128, 53]         --\n",
       "│    └─ZeroPad2d: 2-12                   [4, 128, 258, 109]        --\n",
       "│    └─Conv2d: 2-13                      [4, 128, 128, 53]         262,272\n",
       "│    └─InstanceNorm2d: 2-14              [4, 128, 128, 53]         --\n",
       "│    └─LeakyReLU: 2-15                   [4, 128, 128, 53]         --\n",
       "├─Conv2dLayer: 1-5                       [4, 128, 64, 26]          --\n",
       "│    └─ZeroPad2d: 2-16                   [4, 128, 130, 55]         --\n",
       "│    └─Conv2d: 2-17                      [4, 128, 64, 26]          262,272\n",
       "│    └─InstanceNorm2d: 2-18              [4, 128, 64, 26]          --\n",
       "│    └─LeakyReLU: 2-19                   [4, 128, 64, 26]          --\n",
       "├─Conv2dLayer: 1-6                       [4, 1, 32, 13]            --\n",
       "│    └─ZeroPad2d: 2-20                   [4, 128, 66, 28]          --\n",
       "│    └─Conv2d: 2-21                      [4, 1, 32, 13]            2,049\n",
       "│    └─LeakyReLU: 2-22                   [4, 1, 32, 13]            --\n",
       "├─Sequential: 1-7                        [4, 1]                    --\n",
       "│    └─Linear: 2-23                      [4, 1]                    417\n",
       "│    └─Sigmoid: 2-24                     [4, 1]                    --\n",
       "==========================================================================================\n",
       "Total params: 694,210\n",
       "Trainable params: 694,210\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 43.18\n",
       "==========================================================================================\n",
       "Input size (MB): 14.02\n",
       "Forward/backward pass size (MB): 820.00\n",
       "Params size (MB): 2.78\n",
       "Estimated Total Size (MB): 836.80\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(discriminator, [(4, 1, 1024, 428), (4, 1, 1024, 428)], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 258, 107])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 428])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 512, 428])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = img[0,0,:,:]\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Spectrogram (db)')\n",
    "axs.set_ylabel('freq_bin')\n",
    "axs.set_xlabel('frame')\n",
    "im = axs.imshow(librosa.amplitude_to_db(t), origin='lower', aspect='auto')\n",
    "if None:\n",
    "    axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
