Generator is created!
Initialize generator with xavier type
Discriminator is created!
Initialize discriminator with xavier type
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
The overall number of images equals to 6605
[Epoch 1/200] [Batch 0/1652] [first Mask L1 Loss: 0.00156] [second Mask L1 Loss: 0.05216]
[Epoch 1/200] [Batch 1/1652] [first Mask L1 Loss: 0.00651] [second Mask L1 Loss: 0.07055]
[Epoch 1/200] [Batch 2/1652] [first Mask L1 Loss: 0.00222] [second Mask L1 Loss: 0.03560]
[Epoch 1/200] [Batch 3/1652] [first Mask L1 Loss: 0.00275] [second Mask L1 Loss: 0.04365]
[Epoch 1/200] [Batch 4/1652] [first Mask L1 Loss: 0.00127] [second Mask L1 Loss: 0.03326]
Traceback (most recent call last):
  File "train.py", line 78, in <module>
    trainer.WGAN_trainer(opt)
  File "/workspace/jaejun/inpainting/code/trainer.py", line 129, in WGAN_trainer
    loss_D.backward()
  File "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py", line 149, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 10.76 GiB total capacity; 9.34 GiB already allocated; 15.44 MiB free; 9.60 GiB reserved in total by PyTorch)