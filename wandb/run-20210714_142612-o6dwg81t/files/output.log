
Generator is created!
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
Initialize generator with xavier type
Discriminator is created!
Initialize discriminator with xavier type
The overall number of images equals to 6605
[Epoch 1/200] [Batch 0/1652] [first Mask L1 Loss: 0.00187] [second Mask L1 Loss: 0.06390]
[D Loss: -0.01108] [G Loss: 0.21221] time_left: 61 days, 17:28:38.913651
[Epoch 1/200] [Batch 1/1652] [first Mask L1 Loss: 0.00447] [second Mask L1 Loss: 0.03781]
[D Loss: -0.21104] [G Loss: 0.33606] time_left: 5 days, 13:05:51.509794
[Epoch 1/200] [Batch 2/1652] [first Mask L1 Loss: 0.00654] [second Mask L1 Loss: 0.04316]
[D Loss: 0.47859] [G Loss: 0.13088] time_left: 3 days, 22:16:33.012575
[Epoch 1/200] [Batch 3/1652] [first Mask L1 Loss: 0.00159] [second Mask L1 Loss: 0.03194]
[D Loss: -0.06252] [G Loss: -0.01204] time_left: 3 days, 23:19:34.969494
[Epoch 1/200] [Batch 4/1652] [first Mask L1 Loss: 0.00267] [second Mask L1 Loss: 0.03169]
[D Loss: -0.04856] [G Loss: 0.09621] time_left: 3 days, 23:02:57.694445
[Epoch 1/200] [Batch 5/1652] [first Mask L1 Loss: 0.00275] [second Mask L1 Loss: 0.02491]
[D Loss: 0.05219] [G Loss: 0.05268] time_left: 3 days, 22:40:29.731117
[Epoch 1/200] [Batch 6/1652] [first Mask L1 Loss: 0.00026] [second Mask L1 Loss: 0.01410]
[D Loss: 0.01014] [G Loss: 0.00298] time_left: 4 days, 0:10:50.738521
Traceback (most recent call last):
  File "train.py", line 78, in <module>
    trainer.WGAN_trainer(opt)
  File "/workspace/jaejun/inpainting/code/trainer.py", line 154, in WGAN_trainer
    optimizer_g.step()
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py", line 118, in step
    eps=group['eps'])
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py", line 94, in adam
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
KeyboardInterrupt
[Epoch 1/200] [Batch 7/1652] [first Mask L1 Loss: 0.00039] [second Mask L1 Loss: 0.00527]
[D Loss: -0.00268] [G Loss: 0.01349] time_left: 3 days, 23:03:03.724999
[Epoch 1/200] [Batch 8/1652] [first Mask L1 Loss: 0.00130] [second Mask L1 Loss: 0.00552]
[D Loss: -0.00417] [G Loss: -0.07878] time_left: 4 days, 0:47:03.526167