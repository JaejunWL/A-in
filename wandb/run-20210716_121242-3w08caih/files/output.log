Generator is created!
Initialize generator with xavier type
Discriminator is created!
Initialize discriminator with xavier type
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
The overall number of images equals to 6605
[Epoch 1/200] [Batch 0/1652] [first Mask L1 Loss: 0.00088] [second Mask L1 Loss: 0.04856]
[D Loss: -0.00719] [G Loss: -0.00003] time_left: 54 days, 20:34:19.378242
Traceback (most recent call last):
  File "train.py", line 78, in <module>
    trainer.WGAN_trainer(opt)
  File "/workspace/jaejun/inpainting/code/trainer.py", line 129, in WGAN_trainer
    loss_D.backward()
  File "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py", line 149, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 10.76 GiB total capacity; 9.36 GiB already allocated; 23.44 MiB free; 9.59 GiB reserved in total by PyTorch)
[Epoch 1/200] [Batch 1/1652] [first Mask L1 Loss: 0.00182] [second Mask L1 Loss: 0.02972]
[D Loss: -0.10456] [G Loss: 0.10325] time_left: 8 days, 12:41:11.621719